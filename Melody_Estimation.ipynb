{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "def preprocess_audio(file_name, win_size=31):\n",
    "    # Load the audio file\n",
    "    y, sr = librosa.load(file_name, sr=8000, mono=True)\n",
    "\n",
    "    # Compute the Short-Time Fourier Transform (STFT)\n",
    "    S = np.abs(librosa.stft(y, n_fft=1024, hop_length=80, win_length=1024))\n",
    "\n",
    "    # Convert to decibel scale\n",
    "    db_S = librosa.amplitude_to_db(S, ref=np.max)\n",
    "\n",
    "    # Normalize between 0 and 1\n",
    "    norm_db_S = (db_S - np.min(db_S)) / (np.max(db_S) - np.min(db_S))\n",
    "\n",
    "    # Padding for consistent window sizes\n",
    "    num_frames = norm_db_S.shape[1]\n",
    "    pad_num = num_frames % win_size\n",
    "    if pad_num != 0:\n",
    "        pad_length = win_size - pad_num\n",
    "        padding_feature = np.zeros(shape=(513, pad_length))\n",
    "        norm_db_S = np.concatenate((norm_db_S, padding_feature), axis=1)\n",
    "\n",
    "    # Splitting the frames into windows\n",
    "    x_test = [norm_db_S[:, j:j + win_size].T for j in range(0, norm_db_S.shape[1], win_size)]\n",
    "    x_test = np.array(x_test)\n",
    "    x_test = x_test[..., np.newaxis]  # Add a channel dimension for compatibility with CNNs\n",
    "\n",
    "    return x_test, norm_db_S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_annotations(csv_file_path, hop_length=80, sample_rate=8000, window_size=31):\n",
    "    # Read the CSV file\n",
    "    annotations = pd.read_csv(csv_file_path, header=None, names=['timestamp', 'F0'])\n",
    "\n",
    "    # Calculate the frame number for each timestamp\n",
    "    annotations['frame'] = (annotations['timestamp'] * sample_rate // hop_length).astype(int)\n",
    "\n",
    "    # Drop duplicate frames, keeping only the first occurrence\n",
    "    annotations = annotations.drop_duplicates(subset='frame', keep='first')\n",
    "\n",
    "    # Map F0 values to MIDI (or other desired pitch representation)\n",
    "    annotations['pitch_to_midi'] = annotations['F0'].apply(lambda f: librosa.hz_to_midi(f) if f > 0 else 0)\n",
    "    annotations['label'] = annotations['pitch_to_midi'].apply(lambda f: np.argmin(np.abs(pitch_range - f)))\n",
    "\n",
    "    # Add 'non-voice' label for zero pitch\n",
    "    total_frames = len(annotations)\n",
    "    pad_length = total_frames % window_size\n",
    "    if pad_length != 0:\n",
    "        pad_length = window_size - pad_length\n",
    "        padding_annotations = pd.DataFrame({'frame': range(total_frames, total_frames + pad_length), 'F0': 0, 'label': 0,})\n",
    "        annotations = pd.concat([annotations, padding_annotations], ignore_index=True)\n",
    "\n",
    "    one_hot_labels = np.zeros((annotations.shape[0], len(pitch_range)))\n",
    "    one_hot_labels_vad = np.zeros((annotations.shape[0], 2))\n",
    "    for _, annotation in annotations.iterrows():\n",
    "        one_hot_labels[int(annotation['frame']), int(annotation['label'])] = 1\n",
    "        if(annotation['label'] > 0):\n",
    "          one_hot_labels_vad[int(annotation['frame']), 1] = 1\n",
    "        else:\n",
    "          one_hot_labels_vad[int(annotation['frame']), 0] = 1\n",
    "    y_test = [one_hot_labels[j:j + window_size, :] for j in range(0, one_hot_labels.shape[0], window_size)]\n",
    "    y_test_vad = [one_hot_labels_vad[j:j + window_size, :] for j in range(0, one_hot_labels_vad.shape[0], window_size)]\n",
    "    y_test = np.array(y_test)\n",
    "    y_test_vad = np.array(y_test_vad)\n",
    "    return y_test, y_test_vad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pitch_range = np.arange(38, 83 + 1.0/16, 1.0/16)\n",
    "pitch_range = np.concatenate([np.zeros(1), pitch_range])\n",
    "\n",
    "# Define your directories\n",
    "audio_dir = '/content/drive/MyDrive/Colab_Notebooks/audio_mix/'\n",
    "csv_dir = '/content/drive/MyDrive/Colab_Notebooks/annotation_melody/'\n",
    "\n",
    "# Retrieve a sorted list of audio and CSV files\n",
    "a_files = sorted([os.path.join(audio_dir, file) for file in os.listdir(audio_dir) if file.endswith('.wav')])\n",
    "c_files = sorted([os.path.join(csv_dir, file) for file in os.listdir(csv_dir) if file.endswith('.csv')])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, Dense, Flatten, Dropout, Bidirectional, LSTM, concatenate, TimeDistributed, LeakyReLU, Reshape, add, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "import math\n",
    "def ResNet_Block(input,block_id,filterNum):\n",
    "    ''' Create a ResNet block\n",
    "    Args:\n",
    "        input: input tensor\n",
    "        filterNum: number of output filters\n",
    "    Returns: a keras tensor\n",
    "    '''\n",
    "    x = BatchNormalization()(input)\n",
    "    x = LeakyReLU(0.01)(x)\n",
    "    x = MaxPooling2D((1, 4))(x)\n",
    "\n",
    "    init = Conv2D(filterNum, (1, 1), name='conv'+str(block_id)+'_1x1', padding='same', kernel_initializer='he_normal', use_bias=False)(x)\n",
    "    x = Conv2D(filterNum, (3, 3), name='conv'+str(block_id)+'_1',padding='same',kernel_initializer='he_normal',use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(0.01)(x)\n",
    "    x = Conv2D(filterNum, (3, 3),  name='conv'+str(block_id)+'_2',padding='same',kernel_initializer='he_normal',use_bias=False)(x)\n",
    "\n",
    "    x = add([init, x])\n",
    "    return x\n",
    "\n",
    "num_output = int(45 * 2 ** (math.log(16, 2)) + 2)\n",
    "input = Input(shape=(31, 513, 1))\n",
    "\n",
    "block_1 = Conv2D(64, (3, 3), name='conv1_1', padding='same', kernel_initializer='he_normal', use_bias=False,\n",
    "                  kernel_regularizer=l2(1e-5))(input)\n",
    "block_1 = BatchNormalization()(block_1)\n",
    "block_1 = LeakyReLU(0.01)(block_1)\n",
    "block_1 = Conv2D(64, (3, 3), name='conv1_2', padding='same', kernel_initializer='he_normal', use_bias=False,\n",
    "                  kernel_regularizer=l2(1e-5))(block_1)\n",
    "\n",
    "block_2 = ResNet_Block(input=block_1, block_id=2, filterNum=128)\n",
    "block_3 = ResNet_Block(input=block_2, block_id=3, filterNum=192)\n",
    "block_4 = ResNet_Block(input=block_3, block_id=4, filterNum=256)\n",
    "\n",
    "block_4 = BatchNormalization()(block_4)\n",
    "block_4 = LeakyReLU(0.01)(block_4)\n",
    "block_4 = MaxPooling2D((1, 4))(block_4)\n",
    "block_4 = Dropout(0.5)(block_4)\n",
    "\n",
    "numOutput_P = 2 * block_4.shape[3]\n",
    "output = Reshape((31, numOutput_P))(block_4)\n",
    "\n",
    "output = Bidirectional(LSTM(256, return_sequences=True, recurrent_dropout=0.3, dropout=0.3))(output)\n",
    "output = TimeDistributed(Dense(num_output))(output)\n",
    "output = TimeDistributed(Activation(\"softmax\"), name='output')(output)\n",
    "\n",
    "block_1 = MaxPooling2D((1, 4 ** 4))(block_1)\n",
    "block_2 = MaxPooling2D((1, 4 ** 3))(block_2)\n",
    "block_3 = MaxPooling2D((1, 4 ** 2))(block_3)\n",
    "\n",
    "joint = concatenate([block_1, block_2, block_3, block_4])\n",
    "joint = Conv2D(256, (1, 1), padding='same', kernel_initializer='he_normal', use_bias=False,\n",
    "                kernel_regularizer=l2(1e-5))(joint)\n",
    "joint = BatchNormalization()(joint)\n",
    "joint = LeakyReLU(0.01)(joint)\n",
    "joint = Dropout(0.5)(joint)\n",
    "\n",
    "num_V = joint.shape[3] * 2\n",
    "output_V = Reshape((31, num_V))(joint)\n",
    "\n",
    "output_V = Bidirectional(LSTM(32, return_sequences=True, stateful=False, recurrent_dropout=0.3, dropout=0.3))(\n",
    "    output_V)\n",
    "output_V = TimeDistributed(Dense(2))(output_V)\n",
    "output_V = TimeDistributed(Activation(\"softmax\"))(output_V)\n",
    "\n",
    "output_NS = Lambda(lambda x: x[:, :, 0])(output)\n",
    "output_NS = Reshape((31, 1))(output_NS)\n",
    "output_S = Lambda(lambda x: 1 - x[:, :, 0])(output)\n",
    "output_S = Reshape((31, 1))(output_S)\n",
    "output_VV = concatenate([output_NS, output_S])\n",
    "\n",
    "output_V = add([output_V, output_VV])\n",
    "output_V = TimeDistributed(Activation(\"softmax\"), name='output_V')(output_V)\n",
    "\n",
    "model = Model(inputs=input, outputs=[output, output_V])\n",
    "print(output.shape, output_V.shape)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss={'output': 'categorical_crossentropy', 'output_V': 'categorical_crossentropy'},\n",
    "    loss_weights={'output': 1, 'output_V': 0.5},\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 5):\n",
    "  for i in range(0, 10):\n",
    "    csv_files = c_files[5*i:5*(i+1)]\n",
    "    audio_files = a_files[5*i:5*(i+1)]\n",
    "    combined_spectrograms = []\n",
    "    combined_annotations = []\n",
    "    vad_s = []\n",
    "    for wav_file_path, csv_file_path in zip(audio_files, csv_files):\n",
    "        # Preprocess the audio and annotation files\n",
    "        spectrogram, _ = preprocess_audio(wav_file_path)\n",
    "        annotation, vad = preprocess_annotations(csv_file_path)\n",
    "\n",
    "        # Store the processed data\n",
    "        combined_spectrograms.append(spectrogram)\n",
    "        combined_annotations.append(annotation)\n",
    "        vad_s.append(vad)\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    combined_spectrograms = np.vstack(combined_spectrograms)\n",
    "    combined_annotations = np.vstack(combined_annotations)\n",
    "    vad_s = np.vstack(vad_s)\n",
    "    X_train, X_temp, y_train, y_temp, y_train_vad, y_temp_vad = train_test_split(combined_spectrograms, combined_annotations, vad_s, test_size=0.2, random_state=42)\n",
    "    X_val, X_test, y_val, y_test, y_val_vad, y_test_vad = train_test_split(X_temp, y_temp, y_temp_vad, test_size=0.5, random_state=42)\n",
    "    model.fit(X_train,\n",
    "    {\"output\": y_train, \"output_V\": y_train_vad},\n",
    "    validation_data=(X_val,\n",
    "    {\"output\": y_val, \"output_V\": y_val_vad},),\n",
    "    epochs=5,\n",
    "    verbose=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
